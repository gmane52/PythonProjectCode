{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Dataframes\n",
    "import numpy as np  # Vectores\n",
    "import glob         # gestionar la carga de ficheros csv con el directorio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Load csv de un directorio con pandas\n",
    "\n",
    "directory = r'C:\\Users\\figol\\OneDrive\\Escritorio\\git_gmane\\Proyecto_DAATES\\*.csv'\n",
    "files = glob.glob(directory)\n",
    "listaArchivos = []\n",
    "for file in files:\n",
    "    listaArchivos.append(file)\n",
    "\n",
    "names = ['id','name','geoid','geoname','value','datetime']\n",
    "df_raw = pd.DataFrame(columns=names) \n",
    "\n",
    "i = 0\n",
    "while listaArchivos:\n",
    "    filename = listaArchivos.pop(0)\n",
    "    df_raw_temp = pd.read_csv(filename, sep=';', names=names)\n",
    "    df_raw = pd.concat([df_raw, df_raw_temp], ignore_index=True)\n",
    "\n",
    "del i,df_raw_temp,listaArchivos,files,filename,file,directory # Elimino variables locales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SHAPE:\n",
      "(43805, 6)\n",
      "\n",
      "VALORES NULL:\n",
      "id          0\n",
      "name        0\n",
      "geoid       0\n",
      "geoname     0\n",
      "value       0\n",
      "datetime    0\n",
      "dtype: int64\n",
      "\n",
      "VALORES UNICOS:\n",
      "id              2\n",
      "name            2\n",
      "geoid           2\n",
      "geoname         2\n",
      "value       14922\n",
      "datetime    43801\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Valores únicos en id:\n",
      "['id' '600']\n",
      "Valores únicos en name:\n",
      "['name' 'Precio mercado SPOT Diario España']\n",
      "Valores únicos en geoid:\n",
      "['geoid' '3']\n",
      "Valores únicos en geoname:\n",
      "['geoname' 'España']\n",
      "Valores únicos en value:\n",
      "['value' '66.88' '66' ... '10.06' '63.84' '92.97']\n",
      "Valores únicos en datetime:\n",
      "['datetime' '2019-01-01T00:00:00+01:00' '2019-01-01T01:00:00+01:00' ...\n",
      " '2023-12-31T21:00:00+01:00' '2023-12-31T22:00:00+01:00'\n",
      " '2023-12-31T23:00:00+01:00']\n",
      "\n",
      "TIPOS DE DATOS:\n",
      "id          object\n",
      "name        object\n",
      "geoid       object\n",
      "geoname     object\n",
      "value       object\n",
      "datetime    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "##2.1 PEAK\n",
    "print(\"\\n\" + \"SHAPE:\")\n",
    "print(df_raw.shape)\n",
    "\n",
    "print(\"\\n\" + \"VALORES NULL:\")\n",
    "print(df_raw.isnull().sum())\n",
    "\n",
    "print(\"\\n\" + \"VALORES UNICOS:\")\n",
    "print(df_raw.nunique())\n",
    "print(\"\\n\")\n",
    "for columna in names:\n",
    "    print(f\"Valores únicos en {columna}:\")\n",
    "    print(df_raw[columna].unique())\n",
    "\n",
    "print(\"\\n\" + \"TIPOS DE DATOS:\")\n",
    "print(df_raw.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\figol\\AppData\\Local\\Temp\\ipykernel_1840\\4011592009.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_ws['datetime'] = pd.to_datetime(df_ws['datetime'], errors='coerce') # Casting igual para datetime a timestamp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id           object\n",
      "name         object\n",
      "geoid        object\n",
      "geoname      object\n",
      "value       float64\n",
      "datetime     object\n",
      "dtype: object\n",
      "203.1\n",
      "2019-05-21 04:00:00+02:00\n",
      "5\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\figol\\AppData\\Local\\Temp\\ipykernel_1840\\4011592009.py:5: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df_ws['datetime'] = pd.to_datetime(df_ws['datetime'], errors='coerce') # Casting igual para datetime a timestamp\n"
     ]
    }
   ],
   "source": [
    "# Vemos que el tipo de datos para value y datetime no son los correctos \n",
    "\n",
    "df_ws = df_raw\n",
    "df_ws['value'] = pd.to_numeric(df_ws['value'], errors='coerce') # Casting de la variable 'value' con gestion de errores pasandolo a NA\n",
    "df_ws['datetime'] = pd.to_datetime(df_ws['datetime'], errors='coerce') # Casting igual para datetime a timestamp\n",
    "\n",
    "# Comprovamos.\n",
    "print(df_ws.dtypes)\n",
    "print(df_ws['value'].sample(1).iloc[0])    #Provamos un valor random con sample\n",
    "print(df_ws['datetime'].sample(1).iloc[0])\n",
    "\n",
    "print(df_ws['value'].isnull().sum())\n",
    "print(df_ws['datetime'].isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m df_tmp \u001b[38;5;241m=\u001b[39m df_raw\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m2139\u001b[39m:\u001b[38;5;241m2500\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m df_tmp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdf_tmp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatetime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# Casting igual para datetime a timestamp\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\series.py:1111\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\series.py:1227\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1227\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'datetime'"
     ]
    }
   ],
   "source": [
    "df_ws[df_ws['datetime'].isna()]\n",
    "\n",
    "print('\\n')\n",
    "df_tmp = df_raw.loc[2139:2500, 'datetime']\n",
    "\n",
    "df_tmp['datetime'] = pd.to_datetime(df_tmp['datetime'], errors='coerce') # Casting igual para datetime a timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SHAPE:\n",
      "(43805, 6)\n",
      "\n",
      "VALORES NULL:\n",
      "id          0\n",
      "name        0\n",
      "geoid       0\n",
      "geoname     0\n",
      "value       5\n",
      "datetime    0\n",
      "dtype: int64\n",
      "\n",
      "VALORES UNICOS:\n",
      "id              2\n",
      "name            2\n",
      "geoid           2\n",
      "geoname         2\n",
      "value       14921\n",
      "datetime    43801\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Valores únicos en id:\n",
      "['id' '600']\n",
      "Valores únicos en name:\n",
      "['name' 'Precio mercado SPOT Diario España']\n",
      "Valores únicos en geoid:\n",
      "['geoid' '3']\n",
      "Valores únicos en geoname:\n",
      "['geoname' 'España']\n",
      "Valores únicos en value:\n",
      "[  nan 66.88 66.   ... 10.06 63.84 92.97]\n",
      "Valores únicos en datetime:\n",
      "['datetime' '2019-01-01T00:00:00+01:00' '2019-01-01T01:00:00+01:00' ...\n",
      " '2023-12-31T21:00:00+01:00' '2023-12-31T22:00:00+01:00'\n",
      " '2023-12-31T23:00:00+01:00']\n",
      "\n",
      "TIPOS DE DATOS:\n",
      "id           object\n",
      "name         object\n",
      "geoid        object\n",
      "geoname      object\n",
      "value       float64\n",
      "datetime     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#2 EDA\n",
    "#2.2 Data cleaning1\n",
    "df_ws['value'] = pd.to_numeric(df_ws['value'], errors='coerce') # Casting de la variable 'value' con gestion de errores pasandolo a NA\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3 Descriptive study\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
